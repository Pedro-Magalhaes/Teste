{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.read_csv(\"dataset1.csv\").drop(columns = \"target\")\n",
    "print(dfData.shape)\n",
    "print(dfData.columns)\n",
    "dfData.head()\n",
    "\n",
    "atributos = [ f'V{x}' for x in range(1,14) ]\n",
    "\n",
    "def int_to_float(c):\n",
    "    if isinstance(c, float):\n",
    "        return c\n",
    "    else:\n",
    "        try:\n",
    "            return float(c)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "for atributo in atributos:\n",
    "    dfData[atributo] = dfData[atributo].apply(int_to_float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dfData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLHAR https://docs.python.org/3/library/itertools.html#itertools.combinations\n",
    "# usar combinação do itertools e percorer o vetor ao invés de usar os fors\n",
    "#EXEMPLO itertools:\n",
    "for i in range(1,len(atributos)+1):\n",
    "    comb = list(combinations(atributos,i)) # nao precisa transformar em list, combinations retorna um iterador\n",
    "    print(f\"numero de combinaçoes com {i} elementos = {len(comb)}\") # transformei pra list so pra imprimir o len\n",
    "    # ficaria:\n",
    "    #for comb in combinations(atributos,i):\n",
    "    #    newData = [data[x] for x in comb]\n",
    "print('comb:', list(comb))\n",
    "\n",
    "#exemplo de criação do df apartir de uma combinação\n",
    "for comb in combinations(atributos,13):\n",
    "    newDf = dfData.filter(comb,axis=1)  # copiando apenas os atributos que vamos usar\n",
    "\n",
    "print(newDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1001001)\n",
    "\n",
    "\n",
    "#\n",
    "sample_size=150\n",
    "\n",
    "# \n",
    "best_sil = -999\n",
    "\n",
    "data = dfData\n",
    "\n",
    "for init in ['k-means++', 'random']:\n",
    "    for k in range(3,8):\n",
    "        estimator = KMeans(init=init, n_clusters=k, n_init=10, max_iter=100)\n",
    "        for i in range(1,len(atributos)+1):\n",
    "            for comb in combinations(atributos,i):\n",
    "                newDf = dfData.filter(comb,axis=1)  # copiando apenas os atributos que vamos usar\n",
    "                data = scale(newDf)\n",
    "                estimator.fit(data)\n",
    "                data = scale(dfData)\n",
    "                sil = metrics.silhouette_score(data, estimator.labels_,\n",
    "                                               metric=\"euclidean\",\n",
    "                                               sample_size=sample_size)\n",
    "                if sil > best_sil:\n",
    "                    bestEstimator = estimator\n",
    "                    best_sil = sil\n",
    "                    bestComb = comb\n",
    "                \n",
    "print('better estimator silhouette: %0.4f (%d clusters, %s)' % (best_sil, bestEstimator.n_clusters, bestEstimator.init))\n",
    "print(bestComb)\n",
    "dfData['label'] = bestEstimator.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1001001)\n",
    "\n",
    "\n",
    "#\n",
    "sample_size=150\n",
    "\n",
    "# \n",
    "best_sil = -999\n",
    "\n",
    "data = dfData\n",
    "\n",
    "for init in ['k-means++', 'random']:\n",
    "    for k in range(3,8):\n",
    "        estimator = KMeans(init=init, n_clusters=k, n_init=10, max_iter=100)\n",
    "        for v1 in [0,1]:\n",
    "            for v2 in [0,1]:\n",
    "                for v3 in [0,1]:\n",
    "                    for v4 in [0,1]:\n",
    "                        for v5 in [0,1]:\n",
    "                            for v6 in [0,1]:\n",
    "                                for v7 in [0,1]:\n",
    "                                    for v8 in [0,1]:\n",
    "                                        for v9 in [0,1]:\n",
    "                                            for v10 in [0,1]:\n",
    "                                                for v11 in [0,1]:\n",
    "                                                    for v12 in [0,1]:\n",
    "                                                        for v13 in [0,1]:\n",
    "                                                            data = dfData\n",
    "                                                            if v1 == 0:\n",
    "                                                                data = data.drop(columns = \"V1\")\n",
    "                                                            if v2 == 0:\n",
    "                                                                data = data.drop(columns = \"V2\")\n",
    "                                                            if v3 == 0:\n",
    "                                                                data = data.drop(columns = \"V3\")\n",
    "                                                            if v4 == 0:\n",
    "                                                                data = data.drop(columns = \"V4\")\n",
    "                                                            if v5 == 0:\n",
    "                                                                data = data.drop(columns = \"V5\")\n",
    "                                                            if v6 == 0:\n",
    "                                                                data = data.drop(columns = \"V6\")\n",
    "                                                            if v7 == 0:\n",
    "                                                                data = data.drop(columns = \"V7\")\n",
    "                                                            if v8 == 0:\n",
    "                                                                data = data.drop(columns = \"V8\")\n",
    "                                                            if v9 == 0:\n",
    "                                                                data = data.drop(columns = \"V9\")\n",
    "                                                            if v10 == 0:\n",
    "                                                                data = data.drop(columns = \"V10\")\n",
    "                                                            if v11 == 0:\n",
    "                                                                data = data.drop(columns = \"V11\")\n",
    "                                                            if v12 == 0:\n",
    "                                                                data = data.drop(columns = \"V12\")\n",
    "                                                            if v13 == 0:     \n",
    "                                                                data = data.drop(columns = \"V13\")\n",
    "                                                            if v1==0 and v2==0 and v3==0 and v4==0 and v5==0 and v6==0 and v7==0 and v8==0 and v9==0 and v10==0 and v11==0 and v12==0 and v13==0:\n",
    "                                                                print(\"Sem atributos\")\n",
    "                                                                continue\n",
    "                                                            data = scale(data)\n",
    "                                                            estimator.fit(data)\n",
    "                                                            data = scale(dfData)\n",
    "                                                            sil = metrics.silhouette_score(data, estimator.labels_,\n",
    "                                                                                            metric=\"euclidean\",\n",
    "                                                                                            sample_size=sample_size)\n",
    "                                                            #print('%-10s, k=%d: sil=%0.4f' % (init, k, sil))\n",
    "                                                            #print(\"%d %d %d %d %d %d %d %d %d %d %d %d %d \" % (v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13))\n",
    "                                                            if sil > best_sil:\n",
    "                                                                best_estimator = estimator\n",
    "                                                                best_sil = sil\n",
    "                                                                bestV1 = v1\n",
    "                                                                bestV2 = v2\n",
    "                                                                bestV3 = v3\n",
    "                                                                bestV4 = v4\n",
    "                                                                bestV5 = v5\n",
    "                                                                bestV6 = v6\n",
    "                                                                bestV7 = v7\n",
    "                                                                bestV8 = v8\n",
    "                                                                bestV9 = v9\n",
    "                                                                bestV10 = v10\n",
    "                                                                bestV11 = v11\n",
    "                                                                bestV12 = v12\n",
    "                                                                bestV13 = v13\n",
    "\n",
    "print('better estimator silhouette: %0.4f (%d clusters, %s)' % (best_sil, best_estimator.n_clusters, best_estimator.init))\n",
    "print(\"%d %d %d %d %d %d %d %d %d %d %d %d %d \" % (bestV1, bestV2, bestV3, bestV4, bestV5, bestV6, bestV7, bestV8, bestV9, bestV10, bestV11, bestV12, bestV13))\n",
    "dfData['label'] = best_estimator.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=dfData, vars=['V1'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V2'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V3'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V4'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V5'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V6'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V7'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V8'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V9'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V10'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V11'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V12'], hue='label')\n",
    "plt.show()\n",
    "sns.pairplot(data=dfData, vars=['V13'], hue='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData = pd.read_csv(\"dataset1.csv\").drop(columns = \"target\")\n",
    "print(dfData.shape)\n",
    "print(dfData.columns)\n",
    "dfData.head()\n",
    "\n",
    "atributos = [ f'V{x}' for x in range(1,14) ]\n",
    "\n",
    "def int_to_float(c):\n",
    "    if isinstance(c, float):\n",
    "        return c\n",
    "    else:\n",
    "        try:\n",
    "            return float(c)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "for atributo in atributos:\n",
    "    dfData[atributo] = dfData[atributo].apply(int_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data12 = dfData\n",
    "data12 = dfData[dfData.columns[0:3]]\n",
    "data12 = data12.values\n",
    "\n",
    "data23 = dfData\n",
    "data23 = dfData[dfData.columns[1:3]]\n",
    "data23 = data23.values\n",
    "\n",
    "data34 = dfData\n",
    "data34 = dfData[dfData.columns[2:4]]\n",
    "data34 = data34.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_spectral(df, k):\n",
    "    X = df\n",
    "    model = SpectralClustering(n_clusters=k, affinity='nearest_neighbors', assign_labels='kmeans')\n",
    "    labels = model.fit_predict(X, 0)\n",
    "    df1 = pd.DataFrame(X)\n",
    "    df1['label'] = labels\n",
    "    return df1\n",
    "\n",
    "\n",
    "dfS1 = fit_spectral(data12, k=4)\n",
    "dfS2 = fit_spectral(data23, k=4)\n",
    "dfS3 = fit_spectral(data34, k=4)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n",
    "ax1.scatter(dfS1[0], dfS1[1], c=dfS1.label)\n",
    "ax1.set_title('v1 x v2')\n",
    "plt.suptitle('Spectral', y=0.98)\n",
    "\n",
    "ax2.scatter(dfS2[0], dfS2[1], c=dfS2.label)\n",
    "ax2.set_title('v2 x v3')\n",
    "\n",
    "ax3.scatter(dfS3[0], dfS3[1], c=dfS3.label)\n",
    "ax3.set_title('v3 x v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_agglomerative(df, k):\n",
    "    X = df\n",
    "    model = AgglomerativeClustering(n_clusters=k, affinity='euclidean', compute_full_tree='auto', linkage='ward')\n",
    "    labels = model.fit_predict(X, 0)\n",
    "    df1 = pd.DataFrame(X)\n",
    "    df1['label'] = labels\n",
    "    return df1\n",
    "\n",
    "\n",
    "dfS1 = fit_agglomerative(data12, k=2)\n",
    "dfS2 = fit_agglomerative(data23, k=2)\n",
    "dfS3 = fit_agglomerative(data34, k=2)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n",
    "ax1.scatter(dfS1[0], dfS1[1], c=dfS1.label)\n",
    "ax1.set_title('v1 x v2')\n",
    "\n",
    "ax2.scatter(dfS2[0], dfS2[1], c=dfS2.label)\n",
    "ax2.set_title('v2 x v3')\n",
    "\n",
    "ax3.scatter(dfS3[0], dfS3[1], c=dfS3.label)\n",
    "ax3.set_title('v3 x v4')\n",
    "\n",
    "plt.suptitle('Agglomerative', y=0.98)\n",
    "\n",
    "\n",
    "dfS1 = fit_agglomerative(data12, k=4)\n",
    "dfS2 = fit_agglomerative(data23, k=4)\n",
    "dfS3 = fit_agglomerative(data34, k=4)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n",
    "ax1.scatter(dfS1[0], dfS1[1], c=dfS1.label)\n",
    "ax1.set_title('v1 x v2')\n",
    "\n",
    "ax2.scatter(dfS2[0], dfS2[1], c=dfS2.label)\n",
    "ax2.set_title('v2 x v3')\n",
    "\n",
    "ax3.scatter(dfS3[0], dfS3[1], c=dfS3.label)\n",
    "ax3.set_title('v3 x v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "sample_size=150\n",
    "\n",
    "# \n",
    "best_sil = -999\n",
    "\n",
    "data = dfData\n",
    "\n",
    "for k in range(2,4):\n",
    "    estimator = AgglomerativeClustering(n_clusters=k, affinity='euclidean', compute_full_tree='auto', linkage='ward')\n",
    "    for i in range(1,14):\n",
    "        for comb in combinations(atributos,i):\n",
    "            newDf = dfData.filter(comb,axis=1)  # copiando apenas os atributos que vamos usar\n",
    "            data = scale(newDf)\n",
    "            estimator.fit(data)\n",
    "            data = scale(dfData)\n",
    "            sil = metrics.silhouette_score(data, estimator.labels_,\n",
    "                                               metric=\"euclidean\",\n",
    "                                               sample_size= 150)\n",
    "            if sil > best_sil:\n",
    "                bestEstimator = estimator\n",
    "                best_sil = sil\n",
    "                bestComb = comb\n",
    "                \n",
    "print('better estimator silhouette: %0.4f (%d clusters)' % (best_sil, bestEstimator.n_clusters))\n",
    "print(bestComb)\n",
    "dfData['label'] = bestEstimator.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
